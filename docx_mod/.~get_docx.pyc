#!/usr/bin/python2
# -*- coding: utf-8 -*-
# res_tester -- a tool that checks LP resources for consistency and critical
# errors that cannot be detected during compilation.

# ## setting utf-8 env for stdout
# reload(sys)
# sys.setdefaultencoding('utf-8')
# sys.stdout = codecs.getwriter('utf8')(sys.stdout)
# sys.stderr = codecs.getwriter('utf8')(sys.stderr)

from __future__ import division
from Tkinter import Frame, Tk, Text, IntVar, StringVar, END
from collections import Counter
import codecs
import itertools
import os
import re
import ttk
import zipfile
import sys

if os.name == 'nt':
    # setting utf-8 env for stdout in windows
    reload(sys)
    sys.setdefaultencoding('utf-8')
    sys.stdout = codecs.getwriter('utf8')(sys.stdout)
    sys.stderr = codecs.getwriter('utf8')(sys.stderr)


# paths config
LP_PATH = r'D:\Dev\main\lang-packs'
# LP_PATH = r''


class ResTester(Frame):
    def __init__(self, master):
        '''Main Frame constructor'''
        Frame.__init__(self, master)
        # we need resizable widgets in the main window
        self.grid(sticky='nsew')
        self.columnconfigure(0, weight=1)
        self.columnconfigure(1, weight=1)
        self.rowconfigure(0, weight=1)
        self.make_gui()

    def colorize(self):
        '''This method applies color highlightning to results.'''
        intvar = IntVar()
        patterns = {0: "ERROR\(!!!\).*", 1: "WARNING\(!!\).*",
                    2: "WARNING\(!\).*"}
        patterns2 = {0: 'File:', 1: 'Rule:', 2: 'Found:', 3: 'Duplicates:',
                     4: 'Macro:', 5: 'Line:', 6: '[0-9]+ occurences'}
        styles = {0: ORANGE, 1: YELLOW, 2: LYELLOW}

        # colorizing headers
        for i in range(3):
            start = '1.0'
            while True:
                last_pos = self.text.search(patterns[i], start,
                                            stopindex=END,
                                            count=intvar, regexp=True)
                if not last_pos:
                    break
                end_pos = '{0}+{1}c'.format(last_pos, intvar.get())
                self.text.tag_add(i, last_pos, end_pos)
                self.text.tag_configure(i,
                                        font='TkDefaultFont 10 bold',
                                        background=styles[i])
                start = end_pos
        # colorizing File:, Rule:, Found:
        for i in range(len(patterns2)):
            start = '1.0'
            while True:
                last_pos = self.text.search(patterns2[i], start, stopindex=END,
                                            count=intvar, regexp=True)
                if not last_pos:
                    break
                end_pos = '{0}+{1}c'.format(last_pos, intvar.get())
                self.text.tag_add('labels', last_pos, end_pos)
                self.text.tag_configure('labels',
                                        font='Vernada 10 italic',
                                        background=GREY)
                start = end_pos
        # colorizing OK! results
        start = '1.0'
        while True:
            last_pos = self.text.search('.* OK!', start, stopindex=END,
                                        count=intvar, regexp=True)
            if not last_pos:
                break
            end_pos = '{0}+{1}c'.format(last_pos, intvar.get())
            self.text.tag_add('ok', last_pos, end_pos)
            self.text.tag_configure('ok', font='TkDefaultFont 10 bold',
                                    background=GREEN)
            start = end_pos

    @classmethod
    def get_files_data(cls, files):
        '''This method reads in data from files or zipped files and returns
        a dict with key=filename and value=file_data.
        INPUT: List, OUTPUT: Dict'''
        files_data = {}
        # reading all files data in cape-rule folder
        for filename in files:
            file_data = ''
            if zipfile.is_zipfile(filename):
                zfile = zipfile.ZipFile(filename, 'r')
                zf = zfile.namelist()[0]
                with zfile.open(zf, 'r') as f:
                    for line in f.read().split('\r\n'):
                        file_data += ''.join([line, '\n'])
                    files_data[filename] = file_data
            else:
                with codecs.open(filename, 'r', encoding='utf-8') as f:
                    for line in f.read().split('\r\n'):
                        file_data += ''.join([line, '\n'])
                    files_data[filename] = file_data
        return files_data

    def test_sql(self, sql):
        '''This method tests sql resources.
        INPUT: String, OUTPUT: Dict x 3
        pu_dups_dic) pu dicts are tested for duplicate entries
        sql_low_nam) exception rule headers are tested for uppercase
        sql_rul_dups) exception rules are tested for duplicates
        sql_nam_dups) exception rule names are tested for duplicates'''
        previous = os.getcwd()
        os.chdir(sql)
        sql_files = [f for f in os.listdir(os.getcwd())]
        sql_files_data = {}
        pu_dups_dic = {}
        sql_low_nam = []
        sql_rul_dups = []
        sql_nam_dups = []
        sql_files_data = self.get_files_data(sql_files)

        # testing pu dicts and sql rules
        for filename, data in sql_files_data.items():
            if filename.endswith('csv.zip'):
                try:
                    header = re.sub('[" ]', '', data.split('\n')[0])
                    col = header.split(',').index('WORD')
                    data_list = [l.split(',')[col]
                                 for l in data.split('\n')[1:] if l]
                except:
                    header = re.sub('[" ]', '', data.split('\n')[0])
                    col = header.split(',').index('MODIFIER')
                    data_list = [l.split(',')[col]
                                 for l in data.split('\n')[1:] if l]
                dups = set([d for d in data_list if data_list.count(d) > 1])
                pu_dups_dic[filename] = list(dups)
            elif filename.endswith('sql'):
                rul_lst = [r for r in data.split('/\r')]
                try:
                    rul_nam_lst = [re.search(r'CB:[^\']+', h).group()
                                   for h in rul_lst]
                except:
                    rul_nam_lst = []
                low_nam = set(d for d in rul_nam_lst
                              if re.search(r'[a-z]+', d))
                rul_dups = set([d for d in rul_lst if rul_lst.count(d) > 1])
                nam_dups = set([d for d in rul_nam_lst
                                if rul_nam_lst.count(d) > 1])

        sql_low_nam = list(low_nam)
        sql_rul_dups = list(rul_dups)
        sql_nam_dups = list(nam_dups)
        os.chdir(previous)
        return pu_dups_dic, sql_low_nam, sql_rul_dups, sql_nam_dups

    def test_pos_nfs(self, res_dir):
        '''This method attempts to detect the absense of NormalForm assignment
        in rule's action of pos.rul files.
        INPUT: String, OUTPUT: Dict'''
        previous = os.getcwd()
        working_dir = os.path.join(res_dir, r'cape-rule')
        os.chdir(working_dir)
        pos_files = [f for f in os.listdir(os.getcwd()) if f.startswith('pos')]
        pos_files_data = {}
        pos_files_data = self.get_files_data(pos_files)
        reg_nf = re.compile(r'NormalForm|{:[a-z0-9]+,|:[a-z0-9]+\.GrammarForm[,\s]?|Phase:')
        reg_rule_name = re.compile(r'\s(\w+)\s')
        macro_label = re.compile(r'[A-Za-z_]+')
        nfs_dic = {}
        for filename, data in pos_files_data.items():
            for rule in data.split('Rule:'):
                rule_name = reg_rule_name.search(rule)
                result_block = rule.split('-->')[-1].strip()
                # testing if rule has a correct result block
                # some rules may have '--> <macro>' assignment
                if macro_label.match(result_block):
                    continue
                if not reg_nf.findall(result_block):
                    key = ''.join([filename, rule_name.group()])
                    try:
                        val = re.search(r'[0-9]+', result_block).group()
                        nfs_dic[key] = int(val)
                    except:
                        nfs_dic[key] = ''
        os.chdir(previous)
        return nfs_dic

    def get_files(self, res_dir, rul_type):
        '''This method gets files list of the given directory'''
        working_dir = os.path.join(res_dir, rul_type)
        files = filter(lambda f: not f.startswith('_'),
                            os.listdir(working_dir))
        os.chdir(working_dir)
        return files

    def test_cape_labels(self, res_dir):
        '''This method attempts to detect common errors in label definition.
        INPUT: String, OUTPUT: Dict x 3
        TEST CASES: sle, ml - warning, rle - error
        sle) Rule pattern has a label that does not exist in rule action.
        rle) Rule action has a label that does not exist in rule pattern.
        ml) Labels of mixed upper and lower case.'''
        previous = os.getcwd()
        cape_files = self.get_files(res_dir, r'cape-rule')

        cape_files_data = {}
        sle_dic = {}  # label exists in rule scope but not in result
        rle_dic = {}  # label exists in result but not in scope
        ml_dic = {}  # label has mixed case format
        ml_list = []

        # removing macro files from list, no need to process them
        for i in filter(lambda x: re.search(r'macro.*', x), cape_files):
            cape_files.remove(i)

        cape_files_data = self.get_files_data(cape_files)
        reg_ml_label = re.compile(r'\)(:\w+)')
        reg_label = re.compile(r':[a-z0-9_]+|:[A-Z0-9_][A-Z0-9_]+')
        reg_rule_name = re.compile(r'\b(\w+)\b')
        macro_label = re.compile(r'[A-Za-z_]+')
        for filename, data in cape_files_data.items():
            for rule in data.split('Rule:'):
                rule_name = reg_rule_name.search(rule)
                result_block = rule.split('-->')[-1].strip()
                # detecting mixed case labels first
                if self.islabel.get():
                    ml_labels_set = set(reg_ml_label.findall(rule))
                    ml_list = ([l for l in ml_labels_set if not l.isupper()
                                and not l.islower()])
                    if ml_list:
                        key = ''.join([filename, ' ', rule_name.group()])
                        ml_dic[key] = ml_list
                # testing if rule has a correct result block
                # some rules may have '--> <macro>' assignment
                # detecting sle and rle issues
                condition_block = rule.split('-->')[0]
                if macro_label.match(result_block):
                    rle = set()
                    labels_set = set()
                else:
                    labels_set = set(reg_label.findall(condition_block))
                    results_set = set(reg_label.findall(result_block))
                    rle = results_set - labels_set

                sle = labels_set - results_set

                if sle:
                    key = ''.join([filename, ' ',
                                   rule_name.group()])
                    sle_dic[key] = sle
                if rle:
                    key = ''.join([filename, ' ',
                                   rule_name.group()])
                    rle_dic[key] = rle
        # missing_labels_dic should be a warning of inconsistent code
        # missing_res_labels_dic is a critical error.
        os.chdir(previous)
        return sle_dic, rle_dic, ml_dic

    def test_cape_rul(self, res_dir):
        '''This method tests cape rules for compliance with basic code
        conventions.
        INPUT: String, OUTPUT: Dict x 6
        TEST CASES: fup, comm, llen, mispmacr, sinmacr
        fup) CAPE rule names first char should be Uppercased,
        rule must not be uppercased.
        comm) All CAPE rules should have comments.
        llen) Line length not > 120 chars
        sinmacr) Lonely macro, should be removed.
        upmacr) Macros should be UPPERCASED
        mispmacr) Misplaced macros
        '''
        previous = os.getcwd()
        cape_files = self.get_files(res_dir, r'cape-rule')

        cape_files_data = {}
        cape_files_data = self.get_files_data(cape_files)

        # Check rule name case
        fup = {}
        ruls = {}
        if self.islabel.get():
            for filename, data in cape_files_data.items():
                ruls[filename] = re.findall(r'Rule:\s?[^\s]+', data)
            r = re.compile(r'Rule:\s?[A-Z]+[a-z_]+[A-Za-z0-9_]+')
            for fname in ruls:
                fup[fname] = [rb for rb in ruls[fname] if not r.match(rb)]

        # Check for duplicate rules
        ruls = {}
        for filename, data in cape_files_data.items():
            # ruls = {filename: [list]}
            ruls[filename] = re.findall(r'Rule: ?([A-Za-z0-9_]+)', data)
        ruls_list = [v for v in ruls.values() if v]
        merged = list(itertools.chain.from_iterable(ruls_list))
        dup_ruls = [d for d in Counter(merged).items() if d[1] > 1]

        # turning off missing comments option
        # Check for comments
#        comm = {}
#        ruls = {}
#        for filename, data in cape_files_data.items():
#            # ruls = {filename: [list]}
#            ruls[filename] = [rb for rb in data.split('-->')]
#        rcomm = re.compile(r'\/\/.*\n\/?\*?Rule:')
#        reg_rule_name = re.compile(r'\s(\w+)\s')
#        for filename in ruls:
#            for rb in ruls[filename]:
#                if not rcomm.search(rb):
#                    try:
#                        rule_name = reg_rule_name.search(rb).group()
#                        comm[rule_name.strip(' \n')] = filename
#                    except:
#                        pass
        # Check line length < 120, llen = {line number: filename}
        llen = {}
        if self.islabel.get():
            for filename, data in cape_files_data.items():
                l = 0
                for line in data.split('\n'):
                    l += 1
                    if len(line) > 150:
                        llen[l] = filename
        # Check macro case
        # Check misplaced macros
        macrs_dic = {}
        mispmacr = {}
        rm = re.compile(r'Macro:\s?([A-Za-z0-9_]+)')
        for filename, data in cape_files_data.items():
            l = rm.findall(data)
            if l:
                macrs_dic[filename] = l
                if not filename.startswith('macro'):
                    mispmacr[filename] = ' contains macroes.'
        upmacr = {}
        if self.islabel.get():
            if self.islabel.get():
                for macrs in macrs_dic.values():
                    for m in macrs:
                        rm = re.compile(''.join(['\\b', m, '\\b']))
                        if not m.isupper():
                            upmacr[m] = ' incorrect macro name.'
        # Check for lonely macros
        sinmacr = {}
        for macroes in macrs_dic.values():
            for m in macroes:
                rm = re.compile(''.join(['\\b', m, '\\b']))
                found = 0
                for data in cape_files_data.values():
                    found += len(rm.findall(data))
                    if found > 1:
                        break
                if found <= 1:
                    sinmacr[m] = ' macro is not used.'

        os.chdir(previous)
        # return fup, comm, llen, sinmacr, upmacr, mispmacr
        return fup, llen, sinmacr, upmacr, mispmacr, dup_ruls

    def test_resources(self):
        '''This method invokes different testing methods that were specified\
        by CheckButtons and returns their results'''
        self.currentid = LP_ID[self.lpid.get()]
        self.resources = os.path.join(LP_PATH, self.currentid, r'resources')
        # autotests = os.path.join(LP_PATH, self.currentid, r'autotests')
        sql = os.path.join(LP_PATH, self.currentid, r'installer', r'sql')
        # default empty dicts initialization
        label_t = ({}, {}, {})
        nfs = {}
        sql_t = ({}, {}, {}, {})
        crul_t = ({}, {}, {}, {}, {}, [])
        if self.iscrul.get():
            # sle - scope label errors 0
            # rle - result label errors 1
            # ml - mixed label errors 2
            # returns sle, rle, ml

            # testing cape rules
            # fun - cape rules formatting 0
            # comm - missing cape rule comments 1
            # llen - lines too long 2
            # sinmacr - lonely macroes 3
            # mispmacr - misplaced macroes 4
            # returns fup, comm, llen, sinmacr, upmacr, mispmacr
            label_t = self.test_cape_labels(self.resources)
            crul_t = self.test_cape_rul(self.resources)
        if self.isnf.get():
            # testing missing NormalForms in pos rules
            nfs = self.test_pos_nfs(self.resources)
        if self.issql.get():
            # testing sql resources
            # pu_dups - pu duplicates 0
            # sql_low - sql rule names in lowercase 1
            # sql_rul_dups - sql rule duplicates 2
            # sql_nam_dups - sql rule name duplicates 3
            # returns pu_dups, sql_low, sql_rul_dups, sql_nam_dups
            sql_t = self.test_sql(sql)

        # gathering stats
        # self.errors = len(rle)
        # self.warnings = len(sle) + len(ml) + len(nfs)
        # sle, rle, ml, nfs, pu_dups, sql_low, sql_rul_dups, sql_nam_dups,
        # fup, comm, llen, sinmacr, upmacr, mispmacr
        self.insert_results(label_t, nfs, sql_t, crul_t)

    @classmethod
    def get_line(cls, item, mode):
        '''This method constructs a line out of tuple item.'''
        # for labels lines
        if mode == 'l':
            fname = item[0].split()[0]
            rule = item[0].split()[1].strip('\n')
            # rule = item[0].strip('\n')
            # item[1] might be int() line number
            try:
                label = ' '.join(list(item[1]))
            except:
                label = str(item[1] + 1)
            line = ''.join(['File: ', fname, ' Rule: ', rule, ', ',
                            label, '\n'])
        # for sql lines
        elif mode == 's':
            fname = item[0]
            dups = ''
            for dup in item[1]:
                dups += ''.join(['[ ', dup.decode('utf-8'), ' ]'])
            line = ''.join(['File: ', fname, ' Duplicates: ', dups, '\n'])

        return line


    def get_rules_number(self, dir_path):
        '''This method calculates the number of rules in the provided dir'''
        cape_files = self.get_files(dir_path, r'cape-rule')
        gram_files = self.get_files(dir_path, r'grammar')
        post_files = self.get_files(dir_path, r'post-syntax')
        #morph_files = self.get_files(dir_path, r'morph')
        #lexicon_files = self.get_files(dir_path, r'lexicon')

        this = os.getcwd()
        os.chdir(self.get_target(r'cape-rule'))
        cape_data = self.get_files_data(cape_files)
        os.chdir(this)
        # detected commented out rules
        reg_comm = re.compile(r'\/\*.*\*\/')
        reg_comm1 = re.compile(r'\/\/.*')
        cr = 0
        for v in cape_data.values():
            v0 = reg_comm.sub('', v)
            cr += len(v0.split('Rule:'))
        os.chdir(self.get_target(r'grammar'))
        gram_data = self.get_files_data(gram_files)
        os.chdir(this)
        gr = 0
        for v in gram_data.values():
            v0 = reg_comm.sub('', v)
            gr += len(v0.split('->'))
        os.chdir(self.get_target(r'post-syntax'))
        post_data = self.get_files_data(post_files)
        os.chdir(this)
        pr = 0
        for v in post_data.values():
            v0 = reg_comm.sub('', v)
            pr += len(v0.split('condition:'))

#        os.chdir(self.get_target(r'morph'))
#        morph_data = self.get_files_data(morph_files)
#        os.chdir(this)
#        me = 0

#        for v in morph_data.values():
#            v0 = reg_comm1.sub('', v)
#            me += len(v0.split('PARADIGM:'))
#        os.chdir(self.get_target(r'lexicon'))
#        lexicon_data = self.get_files_data(lexicon_files)
#        os.chdir(this)
#        le = 0
#        for v in lexicon_data.values():
#            v0 = reg_comm1.sub('', v)
#            le += len(v0.split('CSYN'))

        crl = self.new_label_text('Cape rules: ', cr)
        grl = self.new_label_text('Grammar rules: ', gr)
        prl = self.new_label_text('Post-syntax rules: ', pr)
#        mel = self.new_label_text('Morph: ', me)
#        lel = self.new_label_text('Lexicon: ', le)

        return crl, grl, prl, (cr + gr + pr)

    def get_target(self, suffix):
        return os.path.join(LP_PATH, self.currentid, self.resources, suffix)

    def new_label_text(self, text, data):
        return ''.join([text, str(data)])


    def insert_results(self, label_t, nfs, sql_t, crul_t):
        '''This method parses and inserts results into text widget'''
        # label_t(sle, rle, ml),
        # nfs
        # sql_t(pu_dups, sql_low, sql_rul_dups, sql_nam_dups),
        # crul_t(fup, llen, sinmacr, upmacr, mispmacr)
        # <type 'tuple'> <type 'dict'> <type 'tuple'> <type 'tuple'>
        # total number of errors detected
        err = len(label_t) + len(nfs) + len(sql_t) + sum([len(n) for n in crul_t])
        errors = ''.join(['Total issues: ', str(err)])

        self.text.delete('1.0', END)
        sle_label = False
        rle_label = False
        lonely_mcrs = False
        dupl_rules = False

        ml_case = False
        line_case = False
        mac_case = False
        mi_macr = False

        if label_t[2]:
            ml_case = True
            for item in label_t[2].items():
                line = self.get_line(item, 'l')
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['ml'])
        # sle label warnings
        if label_t[0]:
            sle_label = True
            for item in label_t[0].items():
                line = self.get_line(item, 'l')
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['sle'])
        # rle label errors
        if label_t[1]:
            rle_label = True
            for item in label_t[1].items():
                line = self.get_line(item, 'l')
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['rle'])

        # nfs warnings
        if nfs:
            for item in nfs.items():
                line = self.get_line(item, 'l')
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['nfs'])
        else:
            if self.isnf.get():
                self.text.insert('1.0', '\nNormalForms OK!\n')

        # cape rules
        # crul_t(fup, llen, sinmacr, upmacr, mispmacr)
        # long lines
        if crul_t[1]:
            line_case = True
            for item in crul_t[1].items():
                line = ''.join(['File: ', item[1],
                                ' Line: ', str(item[0]), '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['crul_t2'])
        # misplaced macroes
        if crul_t[4] and self.islabel.get():
            mi_macr = True
            for item in crul_t[4]:
                line = ''.join(['File: ', item, crul_t[4][item], '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['crul_t5'])
        # uppercased macroes
        if crul_t[3]:
            mac_case = True
            for item in crul_t[3]:
                line = ''.join(['Macro: ', item, '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['crul_t4'])
        # lonely macroes
        if crul_t[2]:
            lonely_mcrs = True
            for item in crul_t[2]:
                line = ''.join(['Macro: ', item, '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['crul_t3'])
        # duplicate rules
        if crul_t[5]:
            dupl_rules = True
            for item in crul_t[5]:
                line = ''.join([item[0], ', ', str(item[1]), ' occurences\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['crul_t6'])

        # turning off missing comments
        # missing comments
#        if crul_t[1]:
#            for item in crul_t[1].items():
#                line = ''.join(['File: ', item[1], ' Rule: ', item[0], '\n'])
#                self.text.insert('1.0', line)
#            self.text.insert('1.0', ERROR_INFO['crul_t1'])
        # cape rule format
        if crul_t[0]:
            has_errors = False
            for item in crul_t[0].items():
                if item[1]:
                    has_errors = True
                    line = ''.join(['File: ', item[0], ' ', item[1][0], '\n'])
                    self.text.insert('1.0', line)
            if has_errors:
                self.text.insert('1.0', ERROR_INFO['crul_t0'])

#        if not [t for t in crul_t if t]:
#            self.text.insert('1.0', '\nCAPE rules OK!\n')
        # sql_low
        if sql_t[1]:
            for item in sql_t[1]:
                line = ''.join(['File: ngrams.sql Rule: ', item, '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['sql_low'])
        # sql_rul_dups
        if sql_t[2]:
            for item in sql_t[1]:
                line = ''.join(['File: ngrams.sql Rule: ', item, '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['sql_rul_dups'])
        # sql_nam_dups
        if sql_t[3]:
            for item in sql_t[1]:
                line = ''.join(['File: ngrams.sql Rule: ', item, '\n'])
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['sql_nam_dups'])
        # sql errors
        if [l for l in sql_t[0].items() if l[1]]:
            for item in sql_t[0].items():
                if not item[1]:
                    continue
                line = self.get_line(item, 's')
                self.text.insert('1.0', line)
            self.text.insert('1.0', ERROR_INFO['pu_dups'])
        else:
            if self.issql.get():
                self.text.insert('1.0', 'SQL files OK!\n')

        if not sle_label and not rle_label and not lonely_mcrs and not dupl_rules:
            if self.iscrul.get():
                self.text.insert('1.0', '\nCAPE rules OK!\n')

        # name_case = False
        if not ml_case and not line_case and not mac_case and not mi_macr:
            if self.islabel.get():
                self.text.insert('1.0', '\nFormatting OK!\n')

        # adding stats
        try:
            self.Health.destroy()
            self.ErrLabel.destroy()
            self.CapeLabel.destroy()
            self.GramLabel.destroy()
            self.PostLabel.destroy()
#            self.Morph.destroy()
#            self.Lexicon.destroy()
        except:
            pass

        # return crl, grl, prl, mel, lel, (cr + gr + pr)
        lpstats = self.get_rules_number(self.resources)

        self.ErrLabel = ttk.Label(self.rightStats, font='TkDefaultFont 9 bold',
                           text=errors)
        self.ErrLabel.grid(row=5, sticky='we')

        self.CapeLabel = ttk.Label(self.rightStats, font='TkDefaultFont 9',
                                   text=lpstats[0])
        self.CapeLabel.grid(row=6, sticky='we')
        self.GramLabel = ttk.Label(self.rightStats, font='TkDefaultFont 9',
                                   text=lpstats[1])
        self.GramLabel.grid(row=7, sticky='we')
        self.PostLabel = ttk.Label(self.rightStats, font='TkDefaultFont 9',
                                   text=lpstats[2])
        self.PostLabel.grid(row=8, sticky='we')
#        self.Morph = ttk.Label(self.rightStats, font='TkDefaultFont 9',
#                                   text=lpstats[3])
#        self.Morph.grid(row=8, sticky='we')
#        self.Lexicon = ttk.Label(self.rightStats, font='TkDefaultFont 9',
#                                   text=lpstats[4])
#        self.Lexicon.grid(row=9, sticky='we')

        self.colorize()


    def ctrl_a(self, callback):
        '''Select all text in the text widget.
        <overwriting tkinter default 'ctrl + /'>'''
        # checking which text widget has focus
        if self.text is self.focus_get():
            self.text.tag_add('sel', '1.0', 'end')
        return 'break'

    def make_gui(self):
        '''This method creates main gui'''
        options = dict(sticky='nsew', padx=1, pady=1)

        # creating main Frame that holds two child Frames
        self.mainFrame = ttk.Frame(self, borderwidth=2, relief='groove')
        self.mainFrame.grid(columnspan=2, rowspan=2, **options)
        self.mainFrame.grid_columnconfigure(0, weight=1)
        self.mainFrame.grid_columnconfigure(1, weight=1)
        self.mainFrame.grid_rowconfigure(0, weight=1)

        # creating left child Frame on the main Frame, configuring resize
        self.leftFrame = ttk.Frame(self.mainFrame, borderwidth=2,
                                   relief='groove')
        self.leftFrame.grid(row=0, column=0, rowspan=1, columnspan=1,
                            **options)
        self.leftFrame.grid_columnconfigure(0, weight=1)
        self.leftFrame.grid_rowconfigure(0, weight=1)

        # creating right child Frame on the main Frame, configuring resize
        self.rightFrame = ttk.Frame(self.mainFrame, borderwidth=2,
                                    relief='groove')
        self.rightFrame.grid(row=0, column=1, rowspan=1, columnspan=1,
                             **options)
        self.rightFrame.grid_columnconfigure(0, weight=1)
        self.rightFrame.grid_rowconfigure(0, weight=0)
        self.rightFrame.grid_rowconfigure(1, weight=0)
        self.rightFrame.grid_rowconfigure(2, weight=0)
        self.rightFrame.grid_rowconfigure(3, weight=0)
        self.rightFrame.grid_rowconfigure(99, weight=1)

        # creating Text widget that shows analysis results
        self.text = Text(self.leftFrame, font='Verdana 10', undo=True,
                         width=81, takefocus=0)
        self.text.grid(**options)
        self.text.bind('<Control-a>', self.ctrl_a)

        # creating option menu widget
        self.lpid = StringVar()
        self.lp = ttk.OptionMenu(self.rightFrame, self.lpid, *LP_ID)
        self.lp.grid(row=0, column=0, sticky='we')
        self.lpid.set('English')

        # creating Test button, it triggers code analysis
        self.testButton = ttk.Button(self.rightFrame, padding=(0, 3),
                                     text='Test', command=self.test_resources)
        self.testButton.grid(row=1, column=0, sticky='we')

        # creading a scrollbar to the right of the main text widget
        self.scroll = ttk.Scrollbar(self.leftFrame, command=self.text.yview)
        self.text.config(yscrollcommand=self.scroll.set)
        self.scroll.grid(row=0, column=2, sticky='ens')

        # creating check buttons to configure code analysis
        self.issql = IntVar()
        self.sqlCheck = ttk.Checkbutton(self.rightFrame,
                                        text='SQL files', onvalue=1,
                                        offvalue=0, variable=self.issql)
        self.sqlCheck.grid(row=2, column=0, sticky='we')
        self.sqlCheck.invoke()

        self.iscrul = IntVar()
        self.crulCheck = ttk.Checkbutton(self.rightFrame,
                                         text='CAPE rules', onvalue=1,
                                         offvalue=0, variable=self.iscrul)
        self.crulCheck.grid(row=3, column=0, sticky='we')
        self.crulCheck.invoke()

        self.isnf = IntVar()
        self.nfCheck = ttk.Checkbutton(self.rightFrame,
                                       text='Normal forms', onvalue=1,
                                       offvalue=0, variable=self.isnf)
        self.nfCheck.grid(row=4, column=0, sticky='we')
        self.nfCheck.invoke()

        self.islabel = IntVar()
        self.phrCheck = ttk.Checkbutton(self.rightFrame,
                                        text='Formatting', onvalue=1,
                                        offvalue=0, variable=self.islabel)
        self.phrCheck.grid(row=5, column=0, sticky='we')
#        self.phrCheck.invoke()

        # creating stats widget
        self.rightStats = ttk.Frame(self.rightFrame, borderwidth=1,
                                    padding=(3, 3), relief='groove')
        self.rightStats.grid(row=98, **options)

        # exit button
        self.exit = ttk.Button(self.rightFrame, text='Exit', padding=(0, 0),
                               command=root.destroy)
        self.exit.grid(row=99, sticky='swe')


# Error messages pu_dups, sql_low, sql_rul_dups, sql_nam_dups
ERROR_INFO =\
    {'sle': '\nWARNING(!!) Redundant label in rule\'s pattern <-- [CAPE rules]\n',
     'rle': '\nERROR(!!!) Redundant label in rule\'s action <-- [CAPE rules] \n',
     'ml': '\nWARNING(!) Mixed case label is not recommended <-- [Formatting]\n',
     'nfs': '\nERROR(!!!) NormalForm assignment is missing <-- [Normal forms]\n',
     'pu_dups': 'ERROR(!!!) Dictionary duplicate entries detected <-- [SQL files]\n',
     'sql_low': '\nERROR(!!!) Exception rule name is lowercase <-- [SQL files]\n',
     'sql_rul_dups': '\nERROR(!!!) Exception rule duplicate detected <-- [SQL files]\n',
     'sql_nam_dups': '\nERROR(!!!) [SQL files] Exception rule name duplicate detected <-- [SQL files]\n',
     'crul_t6': '\nERROR(!!!) Duplicate rules <-- [CAPE rules]\n',
     'crul_t5': '\nWARNING(!) Misplaced macroes <-- [Formatting]\n',
     'crul_t4': '\nWARNING(!) Incorrect case in macroes <-- [Formatting]\n',
     'crul_t3': '\nWARNING(!) Not used macroes <-- [CAPE rules]\n',
     'crul_t2': '\nWARNING(!) Line too long <-- [Formatting]\n',
     'crul_t1': '\nWARNING(!) Missing comments in rule <-- [CAPE rules]\n',
     'crul_t0': '\nWARNING(!) Uppercased CAPE rule is not recommended <-- [Formatting]\n'}

# LP ids
LP_ID = {'': '', 'Arabic': 'arabic', 'German': 'german', 'English': 'english',
         'Spanish': 'spanish', 'French': 'french', 'Italian': 'italian',
         'Japanese': 'japanese', 'Dutch': 'dutch', 'Portuguese': 'portuguese',
         'Korean': 'korean', 'Russian': 'russian', 'Turkish': 'turkish',
         'Chinese': 'chinese'}

# colors config
ORANGE = '#FFACAC'
YELLOW = '#FFFF99'
LYELLOW = '#FFFFCC'
GREEN = '#CCFF66'
GREY = '#F6F6F6'

# Main app loop
if __name__ == "__main__":
    root = Tk()
    root.title('ResTester 0.3')
    root.geometry('820x500')
    root.columnconfigure(0, weight=1)
    root.rowconfigure(0, weight=1)
    root.resizable(True, True)
    # root.update()
    # you can use ttk themes here ('clam', 'alt', 'classic', 'default')
    # ttk_theme = ttk.Style()
    # ttk_theme.theme_use('clam')

    res_tester = ResTester(root)
    res_tester.mainloop()

# TODO
# 0. Check file encodings (problematic)
# 1. DONE :phr labels assignment
# 2. DONE NormalForm explicit assignment
# 3. DONE Macros defined outside of macro.rul file (needed for some LPs only)
# 4. DONE Enforce lowercase :labels
# 5. DONE Enforce first uppercase char for rules
# 6. DONE Every rule should have comments
# 7. DONE pu dics are checked for duplicates
# 8. DONE ngrams.sql is checked for duplicates rules and rule names
# 9. DONE ngrams.sql is checked for lowercase rule names
# 10. DONE mixed case in labels
# 11. DONE other common label errors
# 13. Post-syntax rules should start with 'Post' string
# 14. DONE line length < 170
# 16. STATS for rules, warnings quantity and overall code grade
# 17. DONE Unused macros
# 18. DONE Macros should be UPPERCASED

# логика простая - чем более специфичное правило - тем оно быстрее 3:40 PM
# потому что в конечном итоге скорость разбора зависит от количества вариантов
# генерируемых набором правил 3:41 PM
# второй аспект - это общее количество правил в LP. чем меньше - тем лучше
